{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ae38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "np.random.seed(34)\n",
    "\n",
    "arrhythmia_df = pd.read_csv('1_data_exploration_arrhythmia.csv')\n",
    "print(arrhythmia_df.shape)\n",
    "# let's level the playing field by collapsing classes 2-16 into one label - Arrhythmia\n",
    "sns.histplot(arrhythmia_df['Class_binary'])\n",
    "\n",
    "# let's stick with the best features output from part 1\n",
    "X = arrhythmia_df.drop(columns=['Class', 'Class_binary', 'Sex_categorical'], inplace=False)\n",
    "#X = SimpleImputer(strategy='most_frequent').fit_transform(X)\n",
    "y = label_binarize(arrhythmia_df['Class_binary'], classes=['No Arrhythmia', 'Arrhythmia']).ravel()\n",
    "\n",
    "arrhythmia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "\n",
    "# since Arrhythmia is a serious condition, I want to evaluate classification by the recall score\n",
    "recall_scorer = make_scorer(recall_score, average='weighted')\n",
    "\n",
    "best_feature_indices = []\n",
    "for clf in [LogisticRegression(), LinearSVC()]:\n",
    "    \n",
    "    selector = RFECV(estimator=clf, cv=5, step=1, scoring=recall_scorer)\n",
    "    scaler = StandardScaler()\n",
    "    selector.fit(scaler.fit_transform(X), y)\n",
    "    \n",
    "    clf_selector_ranking = selector.ranking_\n",
    "    rank1_feature_indices = np.where(selector.ranking_ >= 2)[0]\n",
    "    \n",
    "    best_feature_indices.append(rank1_feature_indices)\n",
    "\n",
    "features_indices_intersection = np.intersect1d(best_feature_indices[0], best_feature_indices[1])\n",
    "print(features_indices_intersection)\n",
    "#features_to_keep = np.array(kbest_feature_names)[features_indices_intersection]\n",
    "# we've removed a majority of less important, highly correlated features\n",
    "#print(set(highly_correlated_features).intersection(features_to_keep))\n",
    "\n",
    "#X_new = X[features_to_keep]\n",
    "#plt.imshow(np.cov(StandardScaler().fit_transform(X_new), rowvar=False), aspect='auto', vmin=-1, vmax=1, cmap='RdBu_r', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44056229",
   "metadata": {},
   "source": [
    "Upon viewing the features' covariance matrix, I considered PCA. With feature elimination removing a chunk of the highly correlated features, we should first investigate classification performance and use PCA as an alternative in the case that we are unsatisfied..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99011011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# let's begin setting the stage for classification\n",
    "split_dict = {'test_size': 0.25, 'shuffle': True}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, **split_dict)\n",
    "\n",
    "# let's also hyper-parameterize the classifier(s)\n",
    "param_grid = {'clf__dual': [True, False], 'clf__tol': [1e-3, 1e-4, 1e-5], 'clf__C': [0.1, 1, 10],\n",
    "                     'clf__class_weight': [None, 'balanced']}\n",
    "gridsearch_params = {'param_grid': param_grid, 'scoring': recall_scorer,\n",
    "                     'return_train_score': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "svc_pipe = Pipeline([('sc', StandardScaler()), ('clf', LinearSVC())])\n",
    "lr_pipe = Pipeline([('sc', StandardScaler()), ('clf', LogisticRegression())])\n",
    "\n",
    "#svc_pipe = Pipeline([('clf', LinearSVC())])\n",
    "#lr_pipe = Pipeline([('clf', LogisticRegression())])\n",
    "\n",
    "#svc_pipe = Pipeline([('sc', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', LinearSVC())])\n",
    "#lr_pipe = Pipeline([('sc', StandardScaler()), ('pca', PCA(n_components=2)), ('clf', LogisticRegression())])\n",
    "\n",
    "#rf_pipe = Pipeline([('sc', StandardScaler()), ('clf')])\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(recall_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "pipeline_dict = {'svc': svc_pipe, 'lr': lr_pipe}\n",
    "\n",
    "for classifier_variation, estimator in pipeline_dict.items():\n",
    "    \n",
    "    search = GridSearchCV(estimator=estimator, **gridsearch_params)\n",
    "    print(classifier_variation)\n",
    "    search.fit(X_train, y_train)\n",
    "    #best = search.best_estimator_\n",
    "    #best.fit(X_train, y_train)\n",
    "    y_pred = search.predict(X_test)\n",
    "    print(recall_score(y_test, y_pred, average='weighted'))\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a1f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca598a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
